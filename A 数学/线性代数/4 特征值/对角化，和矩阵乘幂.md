![[Pasted image 20210913094901.png]]

证明过程略，因此可以获得对角化，$\Lambda$是大写的$\lambda$

对角化的过程中，$\lambda$的顺序，取决于特征向量的顺序

目前已经有3个矩阵拆分了

$A=LU$
$A=QR$
$A=S\Lambda S^{-1}$

能这样拆分的前提是，A有n个线性无关的特征向量，即各不相同的特征值

![[Pasted image 20210913095231.png]]

一个平方的结论

且平方后，特征向量不会变

$A^K=S\Lambda^kS^{-1}$给了我们解出矩阵的幂的方法

# 哪些矩阵可以对角化

如果没有重复的特征值，那么A将有n个线性无关的特征向量

PS：对于一个对角阵，其逆矩阵就是每一个元素变成其自身的倒数。（证明过程，自己把这两个矩阵乘一下）

但是相反，如果有重复的特征值，不一定完全没有线性无关的特征向量，例如I，是有的。（但一般没有）

# 矩阵的幂

一个非常有趣的例子，告诉我们，可以用特征向量去线性表示一个向量。于是如果乘以A，那么就等于x向量的各自乘以对应特征值
![[Pasted image 20210913102607.png]]

## 斐波那契数列

值得自己证明一遍，万一考研就考这道题了呢？确实有助于理解特征值和特征向量